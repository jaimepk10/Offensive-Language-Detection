{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IMKBCaDi30Tz"},"source":["## Proyecto detección de lenguaje ofensivo\n","\n","Es importante procesar las frases que queremos predecir de la misma manera que proceso el documento de entrenamiento para que el modelo puedan encontrar las mismas palabras."]},{"cell_type":"code","source":["#LIBRERIAS\n","import nltk\n","nltk.download('punkt')\n","from sklearn import svm\n","from nltk import TreebankWordTokenizer\n","from nltk.text import Text\n","from nltk.corpus import stopwords\n","from nltk.tokenize import RegexpTokenizer\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.text import Text\n","nltk.download('stopwords')\n","import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","import string\n","import numpy as np\n","from sklearn.svm import LinearSVC\n","from sklearn.datasets import make_classification\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.utils import shuffle\n","\n","\n","\n","ruta = \"INSERTA_LA_RUTA_COMPLETA\"\n","\n","\n","\n","\n","#CONECTAR CON CUENTA DE GOOGLE DRIVE\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#PARA CAMBIAR LA RUTA DEL DIRECTORIO DE ARCHIVOS DONDE ME ENCUENTRO\n","import os \n","os.chdir(ruta)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"lUrxn_ZYTVXR","executionInfo":{"status":"error","timestamp":1676315917940,"user_tz":-60,"elapsed":28274,"user":{"displayName":"Jaime Rubio López","userId":"16175245422637987861"}},"outputId":"2a847114-8617-48fe-d8ec-0bf5d910c8d5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-3b0a3540749d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#PARA CAMBIAR LA RUTA DEL DIRECTORIO DE ARCHIVOS DONDE ME ENCUENTRO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'INSERTA_LA_RUTA_COMPLETA'"]}]},{"cell_type":"code","source":["#CARGO EL TRAIN EN UNA LISTA PARA LUEGO DIVIDIRLO EN DOCUMENTS Y TAGS\n","train = pd.read_csv(\"corpus/train.tsv\", sep='\\t', header=0, encoding = \"ISO-8859-1\")\n","\n","#CARGO EL LEXICON EN UNA LISTA\n","lexicon = pd.read_csv(\"corpus/SHARE.txt\", sep='\\t', encoding = \"utf8\")\n","\n","\n","\n","\n","#FUNCION PAR EL PREPROCESAMIENTO DEL TEXTO PASADO COMO ATRIBUTO\n","def procesar_texto(texto): \n","  text_sinPunt = texto.translate(str.maketrans('', '', string.punctuation))\n","\n","  #tokenizamos el contenido del texto\n","  tokenizer = TreebankWordTokenizer()\n","  tokens = tokenizer.tokenize(text_sinPunt)\n","\n","  #eliminamos las palabras vacías\n","  stop_words = set(stopwords.words('spanish'))\n","  filtered_sentence = [w for w in tokens if not w.lower() in stop_words]\n","\n","  #reducimos las palabras a su raíz\n","  palabras_stem=[]\n","  stemmer = SnowballStemmer(\"spanish\")\n","  for token in filtered_sentence :\n","    palabras_stem.append(stemmer.stem(token))\n","  return \" \".join(palabras_stem)\n"],"metadata":{"id":"Dnq5sMYeTYte"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**UNA VEZ LEIDO EL EXCEL, EN EL CUADRO DE CÓDIGO SIGUIENTE SE DIVIDEN LAS TUPLAS EN LAS CASILLAS DE TEXTO Y ETIQUETAS, LAS ETIQUETAS LAS GUARDAMOS EN TAGS Y EL TEXTO EN DOCUMENTOS, COINCIDIENDO LAS POSICIONES DE CADA TEXTO CON SU ETIQUETA:**"],"metadata":{"id":"lR9T5Qk4g0G5"}},{"cell_type":"code","source":["#RECORRO LAS TUPLAS DEL LEXICON PARA GUARDAR LA INFORMACION EN UNA LISTA\n","lexicon2 = lexicon.itertuples()\n","arrayLexicon = []\n","for fila in lexicon2:\n","  arrayLexicon.append(str(fila[1]))\n","\n","\n","#COMENTARIOS QUE SE VAN A USAR PARA ENTRENAR\n","documentos=[]\n","#ETIQUETAS DE DICHOS DOCUMENTOS\n","tags=[]\n","#ETIQUETAS DE GENERO DE DICHOS DOCUMENTOS\n","tags2=[]\n","#OBTENER LAS TUPLAS DEL ARCHIVO DE ENTRENAMIENTO\n","tuplas=train.itertuples()\n","contadorMujeres = 0\n","contadorHombres = 0\n","\n","#RECORREMOS LAS TUPLAS Y LAS PROCESAMOS\n","for fila in tuplas:\n","  documentos.append(procesar_texto(str(fila[2])))\n","  tags.append(str(fila[3]))\n","  tags2.append(str(fila[4]))"],"metadata":{"id":"p_T22cvjTaEB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**LOS DATOS YA HAN SIDO PREPROCESADOS, GUARDO EL CONTENIDO DE ENTRENAMIENTO EN TEXTO PLANO:**"],"metadata":{"id":"XT9ggE6_m1D4"}},{"cell_type":"code","source":["#GUARDADO DEL TEXTO PROCESADO Y DE LAS ETIQUETAS DEL CUNJUNTO DE ENTRENAMIENTO EN TEXTO PLANO:\n","with open(\"documentosProcesadosTrain.txt\", 'w') as f:\n","  for doc in documentos:\n","    f.write(str(doc))\n","    f.write(\"\\n\")\n","with open(\"etiquetasProcesadasTrain.txt\", 'w') as f:\n","  for tag in tags:\n","    f.write(str(tag))\n","    f.write(\"\\n\")"],"metadata":{"id":"RerslIr2TbZV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**USAMOS EL ALGORITMO DE CLASIFICACION MÁQUINAS DE VECTORES DE SOPORTES (SVM) PARA ENTRENAR EL MODELO:**"],"metadata":{"id":"kBdnO5Pvhyyv"}},{"cell_type":"code","source":["#EXTRAIGO LAS CARACTERÍSTICAS USANDO TF-IDF\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(documentos)\n","\n","#COMBINO LAS DISTINTAS LISTAS DE ETIQUETAS DE ENTRENAMIENTO\n","y = np.vstack((tags, tags2)).T\n","svm = LinearSVC(random_state=42)\n","\n","#CONVIERTO EL MODELO A ENTRENAR EN UN MULTILABEL CLASSIFIER ( CLASIFICADOR MULTI-ETIQUETA )\n","multilabel_classifier = MultiOutputClassifier(svm, n_jobs=-1)\n","\n","#ENTRENAMOS EL MODELO CON EL CLASIFICADOR MULTI-ETIQUETA\n","multilabel_classifier = multilabel_classifier.fit(X, y)"],"metadata":{"id":"azpE_GiRTeJ5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**A PARTIR DE AQUI, AÑADIMOS LA PARTE DE TEST PARA HACER LA PREDICCIÓN SOBRE ÉL**"],"metadata":{"id":"Z5Y8BJGZWnGU"}},{"cell_type":"code","source":["#FUNCION PARA COMPROBAR SEGUN EL LEXICON, SI UN COMENTARIO ES OFENSIVO O NO SEGUN SI SOBREPASA UN UMBRAL\n","umbralLexicon = 3\n","vecesCambiadoPredic = 0\n","\n","def procesarLexicon(pos):\n","  contador = 0\n","  for i in range(len(arrayLexicon)):\n","    if arrayLexicon[i] in textosProcesados[pos]:\n","      contador += 1\n","  if contador > umbralLexicon:\n","    return True\n","  return False\n","\n","\n","\n","\n","#DECLARAMOS UNOS TEXTOS PROCESADOS PARA HACER LAS PREDICCIONES Y OTROS SIN PROCESAR PARA MOSTRARLOS\n","textos = []\n","textosProcesados = []\n","comment_id_test = []\n","gender = []\n","\n","#LEO EL ARCHIVO TEST.TSV\n","test = pd.read_csv(\"corpus/test.tsv\", sep='\\t', header=0, encoding = \"utf8\")\n","tuplas = test.itertuples()\n","\n","#AQUI PROCESO EL TEXTO A PREDECIR GUARGANDO EN UN ARRAY PARA HACER LA PREDICCION\n","for fila in tuplas:\n","  textosProcesados.append(procesar_texto(str(fila[2])))\n","  textos.append(str(fila[2]))\n","  comment_id_test.append(str(fila[1]))\n","  gender.append(str(fila[3]))\n","\n","\n","\n","\n","\n","\n","#DECLARO UN ARRAY PARA GUARDAR LAS ETIQUETAS QUE SE CREARAN AL HACER LAS PREDICCIONES DE CADA FRASE\n","tagsGuardar = []\n","\n","#AQUI COMIENZA LA PREDICCION\n","Y = vectorizer.transform(textosProcesados)\n","y_test_pred = multilabel_classifier.predict(Y)\n","\n","with open(\"anotacionesTest.txt\", 'w') as f:\n","  itPredicc=0\n","  mujeresOFF = 0\n","  hombresOFF = 0\n","  for text in textos:\n","    if \"NON\" in str(y_test_pred[itPredicc]):\n","      var = procesarLexicon(itPredicc)  #LE PASO EL INDICE PARA SABER QUE FRASE ES LA QUE ME HA SALIDO COMO NO OFENSIVA\n","      if var: #SI SE CUMPLE, ESQUE SE HA CAMBIADO LA ETIQUETA DE NON A OFF AL COMPROBAR CUANTAS PALABRAS OFENSIVAS CONTIENE SEGUN EL LEXICON\n","        vecesCambiadoPredic += 1\n","        tagsGuardar.append(\"OFF\")\n","      else:\n","        tagsGuardar.append(str(y_test_pred[itPredicc][0]))\n","    else:\n","      tagsGuardar.append(str(y_test_pred[itPredicc][0]))\n","      if \"woman\" in str(y_test_pred[itPredicc][1]):\n","        mujeresOFF += 1\n","      else:\n","        hombresOFF += 1\n","    #print(text, \"\\n\", y_test_pred[itPredicc][0], \" \", y_test_pred[itPredicc][1])\n","    f.write(text)\n","    f.write(\"\\n\")\n","    f.write(y_test_pred[itPredicc][0])\n","    f.write(\" \")\n","    f.write(y_test_pred[itPredicc][1])\n","    f.write(\"\\n\")\n","    itPredicc+=1\n","\n","\n","print(\"SE HA CAMBIADO LA PREDICCION DE \", vecesCambiadoPredic, \" COMENTARIOS\")\n","print(\"MUJERES A LAS QUE VA DIRIGIDO COMMENTS OFF: \", (mujeresOFF/len(gender))*100)\n","print(\"HOMBRES A LOS QUE VA DIRIGIDO COMMENTS OFF: \", (hombresOFF/len(gender))*100)"],"metadata":{"id":"JDNwbBNCThZ0","executionInfo":{"status":"ok","timestamp":1652875250506,"user_tz":-120,"elapsed":41656,"user":{"displayName":"Jaime Rubio López","userId":"16175245422637987861"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f5f5edab-a66a-4650-9ed6-91e237874ab5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["SE HA CAMBIADO LA PREDICCION DE  23  COMENTARIOS\n","MUJERES A LAS QUE VA DIRIGIDO COMMENTS OFF:  5.291783036895487\n","HOMBRES A LOS QUE VA DIRIGIDO COMMENTS OFF:  5.762163751286197\n"]}]},{"cell_type":"markdown","source":["**PROCEDO A GUARDAR EL RESULTADO DE LA PREDICCION EN UN NUEVO ARCHIVO**"],"metadata":{"id":"gArkmjFe1q6s"}},{"cell_type":"code","source":["#AQUI GUARDO EL RESULTADO DE LA PREDICICON EN UN ARCHIVO .TSV\n","data = {'comment_id': comment_id_test, 'pred': tagsGuardar}\n","df = pd.DataFrame(data, columns = ['comment_id', 'pred'])\n","df.to_csv('corpus/prediction_test.tsv', sep='\\t', index=False)"],"metadata":{"id":"sqC0jf2GorC8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**COMPRUEBO LA PRECISION DE MIS RESULTADOS CON EL CONJUNTO DE EVALUACIÓN gold_label_test**"],"metadata":{"id":"YX8OpYYD11ZY"}},{"cell_type":"code","source":["os.chdir(\"/content/drive/MyDrive/5ºInformática/2ºCUATRIMESTRE/PLN/Prácticas/Práctica 8/corpus\")\n","!python scorer.py gold_label_test.tsv prediction_test.tsv\n","os.chdir(\"/content/drive/MyDrive/5ºInformática/2ºCUATRIMESTRE/PLN/Prácticas/Práctica 8\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRr9xhv6yu2w","executionInfo":{"status":"ok","timestamp":1652873384264,"user_tz":-120,"elapsed":2895,"user":{"displayName":"Jaime Rubio López","userId":"16175245422637987861"}},"outputId":"fd4475fc-0b8f-41e7-f514-a111a796a8a5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GOLD_FILE: gold_label_test.tsv\n","PREDICTION_FILE: prediction_test.tsv\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:604: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask &= (ar1 != a)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:604: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask &= (ar1 != a)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/arraysetops.py:604: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n","  mask &= (ar1 != a)\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n","{'maf': 0.7565527033938739, 'map': 0.8351596369523862, 'mar': 0.7192060438337871, 'mif': 0.8759370865794502, 'mip': 0.8759370865794502, 'mir': 0.8759370865794502, 'avgf': 0.8631065231472472, 'avgp': 0.8680227369929996, 'avgr': 0.8759370865794502}\n"]}]}]}